{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b37a14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00005LE4P</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...</td>\n",
       "      <td>What is the Screen Size of the Laptop?</td>\n",
       "      <td>{'answer_start': [92], 'text': ['14.1\"']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00005LE4P</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...</td>\n",
       "      <td>What is the Processor Speed of the Laptop?</td>\n",
       "      <td>{'answer_start': [25], 'text': ['900 MHz']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00005LE4P</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...</td>\n",
       "      <td>What is the Resolution of the Laptop?</td>\n",
       "      <td>{'answer_start': [102], 'text': ['1024 x 768']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00005NBJB</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Apple iBook Laptop (500-MHz PowerPC G3, 128 MB...</td>\n",
       "      <td>What is the Processor Speed of the Laptop?</td>\n",
       "      <td>{'answer_start': [20], 'text': ['500-MHz']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00005NBIS</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Apple iBook Laptop (500-MHz PowerPC G3, 64 MB ...</td>\n",
       "      <td>What is the Processor Speed of the Laptop?</td>\n",
       "      <td>{'answer_start': [20], 'text': ['500-MHz']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61906</th>\n",
       "      <td>B000EPLRFI</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...</td>\n",
       "      <td>What is the Weight of the Laptop?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61907</th>\n",
       "      <td>B000EPLRFI</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...</td>\n",
       "      <td>What is the Refresh Rate of the Laptop?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61908</th>\n",
       "      <td>B000EPLRFI</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...</td>\n",
       "      <td>What is the Resolution of the Laptop?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61909</th>\n",
       "      <td>B000ETBXB2</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Acer LX.TAT06.045 Nb Dc1.66/512mb/80gb/dvdx2/1...</td>\n",
       "      <td>What is the Weight of the Laptop?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61910</th>\n",
       "      <td>B000ETBXB2</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Acer LX.TAT06.045 Nb Dc1.66/512mb/80gb/dvdx2/1...</td>\n",
       "      <td>What is the Refresh Rate of the Laptop?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61911 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id category                                            context  \\\n",
       "0      B00005LE4P  Laptops  ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...   \n",
       "1      B00005LE4P  Laptops  ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...   \n",
       "2      B00005LE4P  Laptops  ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...   \n",
       "3      B00005NBJB  Laptops  Apple iBook Laptop (500-MHz PowerPC G3, 128 MB...   \n",
       "4      B00005NBIS  Laptops  Apple iBook Laptop (500-MHz PowerPC G3, 64 MB ...   \n",
       "...           ...      ...                                                ...   \n",
       "61906  B000EPLRFI  Laptops  Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...   \n",
       "61907  B000EPLRFI  Laptops  Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...   \n",
       "61908  B000EPLRFI  Laptops  Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...   \n",
       "61909  B000ETBXB2  Laptops  Acer LX.TAT06.045 Nb Dc1.66/512mb/80gb/dvdx2/1...   \n",
       "61910  B000ETBXB2  Laptops  Acer LX.TAT06.045 Nb Dc1.66/512mb/80gb/dvdx2/1...   \n",
       "\n",
       "                                         question  \\\n",
       "0          What is the Screen Size of the Laptop?   \n",
       "1      What is the Processor Speed of the Laptop?   \n",
       "2           What is the Resolution of the Laptop?   \n",
       "3      What is the Processor Speed of the Laptop?   \n",
       "4      What is the Processor Speed of the Laptop?   \n",
       "...                                           ...   \n",
       "61906           What is the Weight of the Laptop?   \n",
       "61907     What is the Refresh Rate of the Laptop?   \n",
       "61908       What is the Resolution of the Laptop?   \n",
       "61909           What is the Weight of the Laptop?   \n",
       "61910     What is the Refresh Rate of the Laptop?   \n",
       "\n",
       "                                                answer  \n",
       "0            {'answer_start': [92], 'text': ['14.1\"']}  \n",
       "1          {'answer_start': [25], 'text': ['900 MHz']}  \n",
       "2      {'answer_start': [102], 'text': ['1024 x 768']}  \n",
       "3          {'answer_start': [20], 'text': ['500-MHz']}  \n",
       "4          {'answer_start': [20], 'text': ['500-MHz']}  \n",
       "...                                                ...  \n",
       "61906                 {'answer_start': [], 'text': []}  \n",
       "61907                 {'answer_start': [], 'text': []}  \n",
       "61908                 {'answer_start': [], 'text': []}  \n",
       "61909                 {'answer_start': [], 'text': []}  \n",
       "61910                 {'answer_start': [], 'text': []}  \n",
       "\n",
       "[61911 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets with pandas\n",
    "import pandas as pd\n",
    "\n",
    "_DATASET_DIR = 'C:/Users/ADMIN/Desktop/DATN/extract_information/data/aveqa_mave/'\n",
    "\n",
    "df_train_positives = pd.read_json(_DATASET_DIR + 'train/mave_positives.jsonl', lines=True)\n",
    "df_train_negatives = pd.read_json(_DATASET_DIR + 'train/mave_negatives.jsonl', lines=True)\n",
    "df_train = pd.concat([df_train_positives, df_train_negatives], axis=0, ignore_index=True)\n",
    "\n",
    "df_val_positives = pd.read_json(_DATASET_DIR + 'eval/mave_positives.jsonl', lines=True)\n",
    "df_val_negatives = pd.read_json(_DATASET_DIR + 'eval/mave_negatives.jsonl', lines=True)\n",
    "df_val = pd.concat([df_val_positives, df_val_negatives], axis=0, ignore_index=True)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916c3b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...</td>\n",
       "      <td>What is the Screen Size of the Laptop?</td>\n",
       "      <td>{'answer_start': [92], 'text': ['14.1\"']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...</td>\n",
       "      <td>What is the Processor Speed of the Laptop?</td>\n",
       "      <td>{'answer_start': [25], 'text': ['900 MHz']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...</td>\n",
       "      <td>What is the Resolution of the Laptop?</td>\n",
       "      <td>{'answer_start': [102], 'text': ['1024 x 768']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Apple iBook Laptop (500-MHz PowerPC G3, 128 MB...</td>\n",
       "      <td>What is the Processor Speed of the Laptop?</td>\n",
       "      <td>{'answer_start': [20], 'text': ['500-MHz']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Apple iBook Laptop (500-MHz PowerPC G3, 64 MB ...</td>\n",
       "      <td>What is the Processor Speed of the Laptop?</td>\n",
       "      <td>{'answer_start': [20], 'text': ['500-MHz']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61906</th>\n",
       "      <td>61906</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...</td>\n",
       "      <td>What is the Weight of the Laptop?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61907</th>\n",
       "      <td>61907</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...</td>\n",
       "      <td>What is the Refresh Rate of the Laptop?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61908</th>\n",
       "      <td>61908</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...</td>\n",
       "      <td>What is the Resolution of the Laptop?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61909</th>\n",
       "      <td>61909</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Acer LX.TAT06.045 Nb Dc1.66/512mb/80gb/dvdx2/1...</td>\n",
       "      <td>What is the Weight of the Laptop?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61910</th>\n",
       "      <td>61910</td>\n",
       "      <td>Laptops</td>\n",
       "      <td>Acer LX.TAT06.045 Nb Dc1.66/512mb/80gb/dvdx2/1...</td>\n",
       "      <td>What is the Refresh Rate of the Laptop?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61911 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id category                                            context  \\\n",
       "0          0  Laptops  ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...   \n",
       "1          1  Laptops  ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...   \n",
       "2          2  Laptops  ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB ...   \n",
       "3          3  Laptops  Apple iBook Laptop (500-MHz PowerPC G3, 128 MB...   \n",
       "4          4  Laptops  Apple iBook Laptop (500-MHz PowerPC G3, 64 MB ...   \n",
       "...      ...      ...                                                ...   \n",
       "61906  61906  Laptops  Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...   \n",
       "61907  61907  Laptops  Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...   \n",
       "61908  61908  Laptops  Apple MacBook MA472LL/A 13.3\" Laptop (2.0 GHz ...   \n",
       "61909  61909  Laptops  Acer LX.TAT06.045 Nb Dc1.66/512mb/80gb/dvdx2/1...   \n",
       "61910  61910  Laptops  Acer LX.TAT06.045 Nb Dc1.66/512mb/80gb/dvdx2/1...   \n",
       "\n",
       "                                         question  \\\n",
       "0          What is the Screen Size of the Laptop?   \n",
       "1      What is the Processor Speed of the Laptop?   \n",
       "2           What is the Resolution of the Laptop?   \n",
       "3      What is the Processor Speed of the Laptop?   \n",
       "4      What is the Processor Speed of the Laptop?   \n",
       "...                                           ...   \n",
       "61906           What is the Weight of the Laptop?   \n",
       "61907     What is the Refresh Rate of the Laptop?   \n",
       "61908       What is the Resolution of the Laptop?   \n",
       "61909           What is the Weight of the Laptop?   \n",
       "61910     What is the Refresh Rate of the Laptop?   \n",
       "\n",
       "                                                answer  \n",
       "0            {'answer_start': [92], 'text': ['14.1\"']}  \n",
       "1          {'answer_start': [25], 'text': ['900 MHz']}  \n",
       "2      {'answer_start': [102], 'text': ['1024 x 768']}  \n",
       "3          {'answer_start': [20], 'text': ['500-MHz']}  \n",
       "4          {'answer_start': [20], 'text': ['500-MHz']}  \n",
       "...                                                ...  \n",
       "61906                 {'answer_start': [], 'text': []}  \n",
       "61907                 {'answer_start': [], 'text': []}  \n",
       "61908                 {'answer_start': [], 'text': []}  \n",
       "61909                 {'answer_start': [], 'text': []}  \n",
       "61910                 {'answer_start': [], 'text': []}  \n",
       "\n",
       "[61911 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_reduced = df_train[['category','context','question','answer']]\n",
    "df_train_reduced['id'] = df_train_reduced.index\n",
    "df_train_reduced.insert(0, 'id', df_train_reduced.pop('id'))\n",
    "df_val_reduced = df_val[['category','context','question','answer']]\n",
    "df_val_reduced['id'] = df_val_reduced.index\n",
    "df_train_reduced.insert(0, 'id', df_train_reduced.pop('id'))\n",
    "df_train_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d0cfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['category', 'context', 'question', 'answer', 'id'],\n",
       "        num_rows: 61911\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['category', 'context', 'question', 'answer', 'id'],\n",
       "        num_rows: 7582\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install datasets\n",
    "# Convert to huggingface dataset\n",
    "from datasets import Dataset, DatasetDict, Features, Value, Sequence\n",
    "\n",
    "answer_feature = {\n",
    "    'answer_start': Sequence(Value('int64')),\n",
    "    'text': Sequence(Value('string'))\n",
    "}\n",
    "\n",
    "features = Features({'category' : Value('string'),\n",
    "                     'context' : Value('string'), \n",
    "                     'question': Value('string'),\n",
    "                     'answer': answer_feature,\n",
    "                     'id': Value('int64')})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train_reduced, features=features)\n",
    "val_dataset = Dataset.from_pandas(df_val_reduced, features=features)\n",
    "\n",
    "raw_datasets = DatasetDict({\"train\":train_dataset, \"val\": val_dataset})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0ad96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  ThinkPad T22 2647 - PIII 900 MHz - RAM 128 MB - HDD 20 GB - DVD - Savage/IX - Win2000 Pro - 14.1\" TFT 1024 x 768 ( XGA ) - black\n",
      "Question:  What is the Screen Size of the Laptop?\n",
      "Answer:  {'answer_start': [92], 'text': ['14.1\"']}\n"
     ]
    }
   ],
   "source": [
    "print(\"Context: \", raw_datasets[\"train\"][0][\"context\"])\n",
    "print(\"Question: \", raw_datasets[\"train\"][0][\"question\"])\n",
    "print(\"Answer: \", raw_datasets[\"train\"][0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c931685a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293ec175900743bfa4b09d53d14621bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/61911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['category', 'context', 'question', 'answer', 'id'],\n",
       "    num_rows: 31178\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"].filter(lambda x: len(x[\"answer\"][\"text\"]) != 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14d056",
   "metadata": {},
   "source": [
    "## Processing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8905bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef17c495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21066a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 407\n",
    "stride = 128\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answer\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "    \n",
    "        if len(answer[\"answer_start\"]) == 0:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            start_char = answer[\"answer_start\"][0]\n",
    "            end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "            sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "            # Find the start and end of the context\n",
    "            idx = 0\n",
    "            while sequence_ids[idx] != 1:\n",
    "                idx += 1\n",
    "            context_start = idx\n",
    "            while sequence_ids[idx] == 1:\n",
    "                idx += 1\n",
    "            context_end = idx - 1\n",
    "\n",
    "            # If the answer is not fully inside the context, label is (0, 0)\n",
    "            if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "                start_positions.append(0)\n",
    "                end_positions.append(0)\n",
    "            else:\n",
    "                # Otherwise it's the start and end token positions\n",
    "                idx = context_start\n",
    "                while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                    idx += 1\n",
    "                start_positions.append(idx - 1)\n",
    "\n",
    "                idx = context_end\n",
    "                while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                    idx -= 1\n",
    "                end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bcafe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d31c9b39aac4cd7a50a9ce3e1d595e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 61924\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"train\"]), len(train_dataset)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "41adab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eb52fed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea588431c7f4440995e5ddc0113b609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7582 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7582, 7590)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = raw_datasets[\"val\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"val\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"val\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56658b",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c144bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c629840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, BertForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64434c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2388387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-aveqa\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    "    per_device_train_batch_size=8,  # Giảm kích thước batch size\n",
    "    per_device_eval_batch_size=8,   # Giảm kích thước batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e88023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
